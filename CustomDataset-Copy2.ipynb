{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fb79885",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62454bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "sequence_length = n_timesteps = 19\n",
    "input_size = [64, 114]\n",
    "hidden_size = [32, 64, 128, 256, 512]\n",
    "num_layers = [1, 2]\n",
    "num_classes = 4\n",
    "batch_size = [32, 64, 128]\n",
    "num_epochs = 10\n",
    "learning_rate = [0.01, 0.001, 0.0001, 0.00001]\n",
    "optimizer = ['sgd', 'rmsprop', 'adam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e411ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 764\n",
    "n_features = 128\n",
    "\n",
    "x = torch.randn(n_samples, n_timesteps, n_features)\n",
    "y = torch.randint(0, 2, (n_samples,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e279e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.data = x\n",
    "        self.label = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.label[idx], dtype=torch.int64)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6f47c80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([764, 19, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f516ccba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([764])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afbc5d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cross-Validation\n",
    "k = 10\n",
    "idx = list(np.random.choice(n_samples, n_samples, replace=False))\n",
    "fold_size = n_samples//k\n",
    "dataset = dict()\n",
    "\n",
    "for i in range(k):\n",
    "    train = idx[:i*fold_size] + idx[(i+1)*fold_size:]\n",
    "    test = idx[i*fold_size:(i+1)*fold_size]\n",
    "    dataset[i] = (CustomDataset(x[train], y[train]), CustomDataset(x[test], y[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8348b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8934,  0.8516, -1.5742,  ...,  0.4017, -0.3243, -0.2149],\n",
       "        [ 1.0225,  0.2800,  0.6403,  ..., -1.3013, -1.7293,  0.1123],\n",
       "        [-1.5453,  0.1417,  1.4023,  ..., -0.9582, -0.9954,  0.5708],\n",
       "        ...,\n",
       "        [ 2.1423,  0.0292,  1.1826,  ..., -0.8704, -0.3447,  0.6466],\n",
       "        [-0.1447,  0.4124, -1.4303,  ..., -0.8386, -0.0705, -0.2782],\n",
       "        [ 0.2907, -0.1864, -0.5096,  ...,  1.1016, -0.1130,  0.5015]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0번째 k-fold 의 trainset의 첫번째 데이터\n",
    "dataset[0][0].data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63bc285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80b8d319",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Recurrent neural network (many-to-one)\n",
    "# save last layer's activation values\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, batch_size, sequence_length):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=False)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        outputs = torch.autograd.Variable(torch.cuda.FloatTensor(self.sequence_length, self.batch_size, self.hidden_size))\n",
    "        h = torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(device) \n",
    "        c = torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        for i in range(self.sequence_length):\n",
    "        # Forward propagate LSTM\n",
    "            curr_seq = x[i:i+1, :, :]\n",
    "            out, (h, c) = self.lstm(curr_seq, (h, c))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "            outputs[i, :, :] = out\n",
    "            # Decode the hidden state of the last time step\n",
    "        out = self.fc(outputs[-1, :, :])\n",
    "        return out, outputs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "280efb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network (many-to-one)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, batch_size, sequence_length):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=False)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states \n",
    "        outputs = torch.autograd.Variable(torch.cuda.FloatTensor(self.sequence_length, self.num_layers, self.batch_size, self.hidden_size))\n",
    "        h = torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(device) \n",
    "        c = torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        for i in range(self.sequence_length):\n",
    "        # Forward propagate LSTM\n",
    "            curr_seq = x[i:i+1, :, :]\n",
    "            out, (h, c) = self.lstm(curr_seq, (h, c))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "            outputs[i, :, :, :] = h\n",
    "            # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[-1, :, :])\n",
    "        return out, outputs\n",
    "    \n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes, batch_size, sequence_length).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(sequence_length, batch_size, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        if epoch == 0 and i == 0:\n",
    "            print(\"data type:\", type(images), type(labels))\n",
    "            print(images.shape, labels.shape)\n",
    "            print(\"images:\", images)\n",
    "            print(\"labels:\", labels)\n",
    "        # Forward pass\n",
    "        o, _ = model(images)\n",
    "        loss = criterion(o, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 3 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "params = dict()\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    params['w'+str(i)] = param\n",
    "    print(param, param.shape)\n",
    "    \n",
    "# Test the model\n",
    "model.eval()\n",
    "y_true = list()\n",
    "y_pred = list()\n",
    "lstm_h = list()\n",
    "last_fc = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(sequence_length, batch_size, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        o, outputs = model(images)\n",
    "        _, predicted = torch.max(o.data, 1)\n",
    "        y_true.extend(labels)\n",
    "        y_pred.extend(predicted)\n",
    "        lstm_h.extend(outputs)\n",
    "        last_fc.extend(o)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')\n",
    "\n",
    "bad_index = list()\n",
    "for i, pred in enumerate(y_pred):\n",
    "    if pred == 0:\n",
    "        bad_index.append(i)\n",
    "print(bad_index)\n",
    "\n",
    "used_samples = len(testset) - (len(testset)%batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a356f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes, batch_size, sequence_length).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "60aa6557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3df09fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2b9bfe8c4c65>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(self.data[idx], dtype=torch.float32)\n",
      "<ipython-input-4-2b9bfe8c4c65>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.label[idx], dtype=torch.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type: <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "torch.Size([18, 64, 128]) torch.Size([64])\n",
      "images: tensor([[[-1.2745e+00, -1.2203e+00,  1.9554e+00,  ...,  1.5681e+00,\n",
      "           1.1967e+00,  5.3070e-01],\n",
      "         [ 1.4619e+00,  1.4328e+00,  1.0010e+00,  ..., -7.0722e-01,\n",
      "           1.1809e+00, -1.4300e+00],\n",
      "         [ 5.7767e-01, -4.0261e-01,  7.3021e-02,  ...,  1.0023e+00,\n",
      "          -9.4646e-01, -1.0641e+00],\n",
      "         ...,\n",
      "         [ 8.7250e-01,  2.1396e-01, -6.0197e-01,  ..., -6.6695e-01,\n",
      "          -1.3337e-01,  8.4785e-02],\n",
      "         [ 1.0351e-01,  4.7204e-01, -1.3595e+00,  ..., -8.7757e-02,\n",
      "           1.1758e-02,  5.1441e-01],\n",
      "         [-8.0490e-01,  7.6909e-01,  1.0566e+00,  ..., -1.1384e-01,\n",
      "          -1.4867e+00,  9.7428e-01]],\n",
      "\n",
      "        [[-2.0316e-01,  1.5572e-01,  1.4202e+00,  ...,  1.6420e+00,\n",
      "           6.6786e-01,  5.8187e-01],\n",
      "         [ 1.0492e+00, -5.1203e-01,  1.8969e+00,  ..., -9.0130e-01,\n",
      "           5.8423e-01,  3.0711e-01],\n",
      "         [ 1.5174e+00, -1.3090e+00, -2.4904e-01,  ..., -6.2884e-02,\n",
      "          -1.5822e+00,  1.1821e-01],\n",
      "         ...,\n",
      "         [ 7.9283e-01,  1.7558e+00,  8.7857e-01,  ..., -1.6880e+00,\n",
      "           1.1850e-01, -3.3107e-01],\n",
      "         [ 2.4990e-01, -4.5174e-01, -1.4983e-01,  ...,  1.9575e+00,\n",
      "           1.0714e+00, -4.7746e-01],\n",
      "         [ 1.1561e-01,  2.7965e-01,  1.5052e+00,  ..., -1.3790e+00,\n",
      "           5.9302e-01, -1.3061e+00]],\n",
      "\n",
      "        [[ 2.1525e+00,  1.2692e+00, -1.3213e+00,  ..., -6.7050e-01,\n",
      "           3.8780e-01,  1.2768e-01],\n",
      "         [ 4.3317e-01, -3.5887e-01,  4.6883e-01,  ..., -7.0770e-01,\n",
      "           1.8415e+00, -6.6748e-01],\n",
      "         [-1.0352e+00,  5.2814e-01, -4.5989e-01,  ..., -8.3749e-01,\n",
      "           1.2861e-01,  1.3936e+00],\n",
      "         ...,\n",
      "         [ 1.4362e+00,  2.3989e-01,  1.6138e+00,  ..., -1.3680e+00,\n",
      "          -7.3959e-01, -2.4303e-02],\n",
      "         [-1.6282e+00, -1.2081e+00,  9.6421e-01,  ..., -1.9495e+00,\n",
      "          -8.8687e-02,  3.0441e-01],\n",
      "         [-1.1728e+00, -1.0054e+00, -4.6229e-01,  ...,  7.2121e-01,\n",
      "           7.9685e-01,  1.1980e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0764e-01, -3.3713e-01,  1.5790e+00,  ...,  5.2582e-02,\n",
      "          -4.7093e-01,  6.1505e-01],\n",
      "         [ 5.7037e-01,  2.5938e+00, -5.0824e-01,  ..., -2.1763e-01,\n",
      "           1.8154e-01,  8.1720e-04],\n",
      "         [-1.4698e+00,  6.0101e-01,  2.1889e+00,  ..., -1.5746e-01,\n",
      "           1.7721e-01, -3.0733e-01],\n",
      "         ...,\n",
      "         [-1.2185e+00, -5.4081e-01, -1.0688e+00,  ...,  6.8419e-01,\n",
      "          -2.1959e+00,  1.2105e+00],\n",
      "         [-4.7032e-01,  2.7778e-01,  1.2511e+00,  ..., -1.7283e-01,\n",
      "          -1.2413e+00,  5.3968e-01],\n",
      "         [-9.8121e-01,  8.6194e-01,  2.5899e+00,  ..., -3.8619e-01,\n",
      "           5.8585e-01, -1.0546e-01]],\n",
      "\n",
      "        [[-4.4551e-01,  1.0489e-01, -1.6487e+00,  ..., -4.9171e-01,\n",
      "          -3.0642e-01,  3.2919e-01],\n",
      "         [-2.8592e-01,  1.6759e+00,  4.9579e-02,  ...,  1.5798e+00,\n",
      "           2.0755e+00,  1.6338e+00],\n",
      "         [-1.8643e-01, -5.3650e-02, -1.2435e+00,  ..., -7.6058e-01,\n",
      "          -7.6650e-01,  9.1113e-01],\n",
      "         ...,\n",
      "         [ 5.1939e-01,  5.6392e-01, -1.6114e+00,  ...,  3.3765e-01,\n",
      "          -1.7604e-02,  1.4191e+00],\n",
      "         [-1.1298e+00,  9.6553e-01, -9.5620e-01,  ..., -1.4429e-01,\n",
      "          -6.4723e-01,  1.4728e+00],\n",
      "         [-5.4336e-01, -3.4219e-01, -8.5832e-01,  ..., -4.9014e-01,\n",
      "          -1.6784e-01,  4.6048e-01]],\n",
      "\n",
      "        [[ 2.1803e-01, -4.5085e-01,  1.3602e+00,  ..., -2.3421e-01,\n",
      "           2.6877e-01,  1.1307e+00],\n",
      "         [ 1.8767e+00,  1.2819e-01,  1.6802e+00,  ...,  6.7501e-01,\n",
      "          -1.0224e+00,  1.4239e-01],\n",
      "         [ 3.3287e-01, -1.1684e+00,  3.8442e-01,  ..., -5.4277e-01,\n",
      "           7.9384e-01,  1.3939e+00],\n",
      "         ...,\n",
      "         [ 7.1730e-01, -4.2821e-01, -1.8557e+00,  ...,  4.1078e-01,\n",
      "           4.6732e-02,  1.3240e+00],\n",
      "         [-8.5648e-01, -4.0472e-01, -2.5579e+00,  ..., -5.3219e-01,\n",
      "           1.0818e+00,  5.6634e-01],\n",
      "         [ 1.8158e+00,  1.4874e+00, -3.1062e-01,  ...,  1.2732e+00,\n",
      "           5.5464e-02, -2.8293e-01]]], device='cuda:0')\n",
      "labels: tensor([0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "Epoch [1/10], Step [3/9], Loss: 0.6911\n",
      "Epoch [1/10], Step [6/9], Loss: 0.6990\n",
      "Epoch [1/10], Step [9/9], Loss: 0.7110\n",
      "Epoch [2/10], Step [3/9], Loss: 0.7311\n",
      "Epoch [2/10], Step [6/9], Loss: 0.6813\n",
      "Epoch [2/10], Step [9/9], Loss: 0.6844\n",
      "Epoch [3/10], Step [3/9], Loss: 0.7771\n",
      "Epoch [3/10], Step [6/9], Loss: 0.6992\n",
      "Epoch [3/10], Step [9/9], Loss: 0.6891\n",
      "Epoch [4/10], Step [3/9], Loss: 0.6906\n",
      "Epoch [4/10], Step [6/9], Loss: 0.6969\n",
      "Epoch [4/10], Step [9/9], Loss: 0.6942\n",
      "Epoch [5/10], Step [3/9], Loss: 0.7126\n",
      "Epoch [5/10], Step [6/9], Loss: 0.6942\n",
      "Epoch [5/10], Step [9/9], Loss: 0.7191\n",
      "Epoch [6/10], Step [3/9], Loss: 0.6962\n",
      "Epoch [6/10], Step [6/9], Loss: 0.7145\n",
      "Epoch [6/10], Step [9/9], Loss: 0.6845\n",
      "Epoch [7/10], Step [3/9], Loss: 0.7058\n",
      "Epoch [7/10], Step [6/9], Loss: 0.7153\n",
      "Epoch [7/10], Step [9/9], Loss: 0.6936\n",
      "Epoch [8/10], Step [3/9], Loss: 0.6946\n",
      "Epoch [8/10], Step [6/9], Loss: 0.6930\n",
      "Epoch [8/10], Step [9/9], Loss: 0.6937\n",
      "Epoch [9/10], Step [3/9], Loss: 0.6880\n",
      "Epoch [9/10], Step [6/9], Loss: 0.7045\n",
      "Epoch [9/10], Step [9/9], Loss: 0.6885\n",
      "Epoch [10/10], Step [3/9], Loss: 0.6942\n",
      "Epoch [10/10], Step [6/9], Loss: 0.6901\n",
      "Epoch [10/10], Step [9/9], Loss: 0.6959\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(sequence_length, batch_size, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        if epoch == 0 and i == 0:\n",
    "            print(\"data type:\", type(images), type(labels))\n",
    "            print(images.shape, labels.shape)\n",
    "            print(\"images:\", images)\n",
    "            print(\"labels:\", labels)\n",
    "        # Forward pass\n",
    "        o, _ = model(images)\n",
    "        loss = criterion(o, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 3 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba1f1ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1116,  0.1171,  0.0116,  ...,  0.0521,  0.0767, -0.0293],\n",
      "        [ 0.0958,  0.1450,  0.1369,  ...,  0.0936,  0.2016,  0.0890],\n",
      "        [ 0.1199,  0.0392,  0.0700,  ...,  0.0016,  0.1653,  0.0778],\n",
      "        ...,\n",
      "        [-0.0356, -0.0490,  0.1948,  ..., -0.0351, -0.0617,  0.0055],\n",
      "        [ 0.0009,  0.1043, -0.0416,  ...,  0.0171,  0.0218,  0.0369],\n",
      "        [-0.0486,  0.0445,  0.0326,  ...,  0.0463,  0.0468, -0.0044]],\n",
      "       device='cuda:0', requires_grad=True) torch.Size([1024, 128])\n",
      "Parameter containing:\n",
      "tensor([[ 0.1035, -0.0120,  0.0789,  ..., -0.0713,  0.0720,  0.0265],\n",
      "        [-0.0688,  0.2744,  0.2545,  ...,  0.0381,  0.0871,  0.0254],\n",
      "        [ 0.0359, -0.0419,  0.0594,  ..., -0.0565,  0.0005,  0.0746],\n",
      "        ...,\n",
      "        [ 0.0407,  0.0618,  0.0810,  ...,  0.1242, -0.0864, -0.0119],\n",
      "        [ 0.0846, -0.0222,  0.0177,  ..., -0.1169,  0.0031,  0.0121],\n",
      "        [ 0.0998,  0.0637,  0.1303,  ..., -0.0862, -0.0238,  0.0387]],\n",
      "       device='cuda:0', requires_grad=True) torch.Size([1024, 256])\n",
      "Parameter containing:\n",
      "tensor([-0.0625,  0.0874, -0.1687,  ..., -0.1462, -0.0504, -0.0926],\n",
      "       device='cuda:0', requires_grad=True) torch.Size([1024])\n",
      "Parameter containing:\n",
      "tensor([-0.0806,  0.0039, -0.1761,  ..., -0.1676, -0.1376, -0.1096],\n",
      "       device='cuda:0', requires_grad=True) torch.Size([1024])\n",
      "Parameter containing:\n",
      "tensor([[ 0.1121, -0.1266, -0.0720,  ..., -0.0033,  0.1742, -0.0529],\n",
      "        [ 0.0457,  0.0566,  0.0536,  ...,  0.0399, -0.1336,  0.0885],\n",
      "        [-0.0629, -0.0955,  0.0012,  ..., -0.0359,  0.1151, -0.0554],\n",
      "        ...,\n",
      "        [-0.0097, -0.0819,  0.0677,  ...,  0.1811, -0.0604, -0.0463],\n",
      "        [ 0.0962,  0.0899,  0.0870,  ..., -0.1857,  0.0436, -0.0596],\n",
      "        [-0.0107,  0.0370,  0.0384,  ..., -0.0898, -0.1716, -0.0816]],\n",
      "       device='cuda:0', requires_grad=True) torch.Size([1024, 256])\n",
      "Parameter containing:\n",
      "tensor([[-0.0150, -0.1041,  0.0232,  ...,  0.1809,  0.0204,  0.1307],\n",
      "        [-0.0229,  0.1123, -0.0195,  ..., -0.1161,  0.0172, -0.1121],\n",
      "        [-0.0007, -0.1539, -0.0756,  ...,  0.1185,  0.0838,  0.0963],\n",
      "        ...,\n",
      "        [ 0.0637, -0.1056,  0.0219,  ...,  0.1439, -0.0341, -0.0260],\n",
      "        [-0.0094, -0.1947, -0.0491,  ...,  0.1175,  0.0491,  0.0970],\n",
      "        [-0.1138, -0.0376, -0.1450,  ...,  0.0467,  0.0196, -0.0482]],\n",
      "       device='cuda:0', requires_grad=True) torch.Size([1024, 256])\n",
      "Parameter containing:\n",
      "tensor([-0.1292, -0.0736, -0.1629,  ..., -0.1432, -0.0994, -0.1611],\n",
      "       device='cuda:0', requires_grad=True) torch.Size([1024])\n",
      "Parameter containing:\n",
      "tensor([-0.1613,  0.0268, -0.1026,  ..., -0.2249, -0.1073, -0.1079],\n",
      "       device='cuda:0', requires_grad=True) torch.Size([1024])\n",
      "Parameter containing:\n",
      "tensor([[-1.2416e-03,  2.7989e-03, -4.1044e-02,  5.4276e-03, -4.8916e-02,\n",
      "         -1.7520e-02,  9.1756e-04, -6.6619e-02,  3.1648e-02, -3.4081e-02,\n",
      "          2.0682e-03, -3.8989e-02, -5.7034e-02,  1.4947e-02, -9.6578e-03,\n",
      "          6.8533e-03, -4.3300e-02,  3.8201e-02, -6.7928e-02,  1.5286e-02,\n",
      "         -5.8086e-04, -4.2423e-02,  2.3218e-03, -4.0815e-02,  1.6972e-03,\n",
      "          2.9616e-02, -8.6210e-03, -1.5590e-02,  3.2174e-02, -5.1772e-02,\n",
      "          2.2257e-02, -3.0955e-02,  6.1592e-02,  3.7509e-03, -1.9297e-02,\n",
      "          7.2993e-03,  3.8328e-02, -3.9399e-02, -3.3954e-02,  3.8732e-02,\n",
      "         -6.6329e-02,  5.7204e-03,  4.0670e-03,  3.8495e-04,  3.2100e-02,\n",
      "          2.0478e-02,  7.9198e-03, -1.1092e-02,  3.8101e-03, -4.4952e-02,\n",
      "         -3.7917e-02,  6.5226e-02,  1.6186e-02, -2.0990e-02, -3.5250e-02,\n",
      "          6.9012e-03, -1.4391e-02, -2.1928e-03,  6.7809e-04, -7.9737e-03,\n",
      "          2.2990e-02,  3.9879e-02,  2.6262e-02, -3.0753e-02,  1.5657e-02,\n",
      "          6.5631e-04,  5.6989e-02, -1.2602e-02, -3.4752e-02, -2.2572e-02,\n",
      "         -6.0106e-02, -1.6845e-02, -4.3561e-03,  3.7870e-02, -6.0492e-02,\n",
      "         -3.5653e-02, -8.5048e-02,  2.8855e-02, -3.1925e-02, -1.6479e-02,\n",
      "         -5.9265e-03, -1.1568e-02,  7.0966e-03,  3.2805e-02, -3.8581e-05,\n",
      "          8.1804e-02, -1.5664e-02, -4.9420e-02, -2.5380e-03,  2.4391e-02,\n",
      "         -3.5951e-02,  1.3925e-02,  9.5151e-03, -3.2148e-02, -2.2623e-02,\n",
      "          5.7262e-02,  2.8629e-02,  3.6598e-02, -1.3692e-02,  6.5230e-02,\n",
      "          3.5430e-03, -3.8104e-03,  2.0280e-03, -1.1158e-02, -1.8987e-06,\n",
      "          4.2957e-03, -2.8018e-03,  1.3003e-02,  2.6114e-03, -2.7994e-02,\n",
      "         -1.7067e-02, -2.7442e-02,  3.5468e-03,  3.9780e-03,  2.2313e-02,\n",
      "         -1.7209e-02,  3.2279e-02, -2.8689e-02, -4.8865e-04,  2.2694e-02,\n",
      "         -4.5186e-03,  6.8776e-03,  5.4486e-02,  1.0077e-02,  5.6419e-02,\n",
      "         -3.7118e-02, -6.6874e-03,  1.2786e-03, -5.3780e-02,  2.3238e-03,\n",
      "         -1.4479e-02, -2.6844e-02,  5.4467e-02, -3.3805e-02,  3.2853e-02,\n",
      "          5.1774e-02,  1.8467e-02,  2.5835e-02, -2.1956e-02,  4.8985e-02,\n",
      "          2.5723e-02,  6.7456e-02, -5.3197e-02, -1.0952e-02, -4.6640e-02,\n",
      "          3.7810e-02, -1.2115e-02, -3.5699e-02, -2.6510e-02, -1.9160e-03,\n",
      "          4.6519e-02,  1.9967e-03, -2.5554e-02, -1.7423e-02, -4.2325e-03,\n",
      "         -4.8415e-02, -9.9014e-03, -2.2820e-02, -1.5406e-02, -4.7767e-05,\n",
      "          9.0813e-04, -2.3225e-02, -4.3149e-02, -3.8017e-02, -1.6651e-02,\n",
      "         -4.2163e-02,  4.1953e-02,  2.5419e-02, -2.3642e-02, -3.9773e-02,\n",
      "         -1.1160e-02,  3.6625e-02, -2.8222e-02,  3.9188e-02,  7.3635e-02,\n",
      "          2.0316e-02, -5.1992e-02, -1.7486e-02, -2.0326e-02, -1.8087e-02,\n",
      "         -3.8993e-02, -4.8808e-02,  1.7470e-03, -1.6015e-02, -2.7383e-02,\n",
      "          4.3844e-03,  1.3327e-02, -5.7076e-04, -8.9662e-03, -6.3473e-03,\n",
      "          4.8759e-02,  1.3840e-02, -5.6565e-03, -6.5274e-02,  3.7462e-02,\n",
      "         -6.1950e-02,  7.3200e-02,  1.5262e-02,  2.2651e-02, -4.3849e-03,\n",
      "         -2.7199e-02,  4.2854e-02, -1.0395e-02, -1.3180e-02, -3.4605e-02,\n",
      "          1.1068e-02,  1.0182e-02,  6.9557e-02, -1.0300e-02, -3.5096e-02,\n",
      "         -5.4825e-03,  1.9373e-02, -7.4738e-03, -2.0210e-02, -1.4587e-02,\n",
      "         -6.6442e-03, -4.6076e-03, -6.0640e-02, -2.7988e-02, -2.0859e-02,\n",
      "         -8.4569e-03,  7.4198e-02,  7.6904e-02, -2.5439e-02, -4.9875e-02,\n",
      "         -8.2666e-03, -8.8223e-03, -4.3715e-02,  3.7614e-03, -3.4667e-02,\n",
      "          1.5930e-02,  3.9542e-02,  5.7552e-03, -6.8642e-02,  5.1541e-02,\n",
      "          3.8446e-02,  6.7406e-02,  2.9329e-02,  2.9672e-02,  3.7083e-02,\n",
      "          8.2629e-02, -4.1930e-02, -2.4392e-02, -3.7296e-02,  8.8739e-03,\n",
      "         -8.0109e-02, -7.8275e-02,  9.9117e-03,  6.5760e-03,  1.6810e-02,\n",
      "         -5.1381e-02, -3.2726e-02, -7.6712e-03,  1.8986e-02, -7.1076e-02,\n",
      "          1.5944e-02],\n",
      "        [-3.0139e-02,  2.4391e-03, -3.6753e-02, -1.2820e-04, -2.9454e-02,\n",
      "         -4.5604e-02,  9.8411e-03,  1.2033e-02, -2.1690e-02, -4.3316e-02,\n",
      "          5.8917e-03, -1.8568e-02, -2.8327e-02,  1.2259e-02,  1.8215e-02,\n",
      "         -2.1994e-02, -2.3939e-02,  2.0034e-02, -1.2141e-02,  3.5900e-03,\n",
      "          3.8655e-04,  3.6992e-02,  9.5854e-03,  3.4204e-03, -3.3948e-02,\n",
      "          9.9745e-03,  5.1878e-04,  4.4559e-02, -1.4988e-02, -3.7545e-03,\n",
      "          9.0699e-03,  4.8901e-02,  2.2084e-02,  3.8570e-02, -1.7764e-02,\n",
      "         -3.1915e-03, -7.6614e-03, -2.4489e-02, -8.8598e-05, -1.0647e-02,\n",
      "          1.7205e-02, -1.7742e-02,  5.5589e-02, -3.4113e-02,  1.5842e-02,\n",
      "          1.1362e-02, -4.9353e-02, -4.2970e-02,  2.7215e-02, -4.1853e-02,\n",
      "          3.6575e-02,  5.4095e-02, -1.1603e-03,  7.7857e-03, -2.9609e-02,\n",
      "          1.1454e-02,  2.0859e-02, -7.1692e-03,  4.4265e-02, -1.8329e-02,\n",
      "          8.7798e-02,  2.3831e-02,  5.0942e-02,  1.6692e-02,  9.4732e-03,\n",
      "          1.0666e-02,  2.2429e-02, -5.9681e-02,  4.7317e-02, -1.4562e-02,\n",
      "          3.4713e-02, -1.3711e-02,  1.0017e-02,  1.0818e-02, -5.8818e-03,\n",
      "          9.2967e-03, -5.2454e-04, -1.3106e-02, -3.8590e-02, -8.2286e-03,\n",
      "          5.0553e-03, -4.1198e-02, -2.8803e-03,  2.8594e-02, -2.2871e-02,\n",
      "          6.1346e-03, -2.3957e-02,  2.1710e-02,  4.0821e-02, -2.6546e-02,\n",
      "          2.8292e-02, -2.1836e-03,  1.5389e-02,  1.0074e-02,  1.8820e-02,\n",
      "          5.5623e-02,  2.3688e-02, -2.7949e-02, -1.7108e-02,  2.0263e-02,\n",
      "          6.8308e-02, -3.9935e-02,  2.9422e-02,  2.9080e-03,  1.8248e-02,\n",
      "          3.7671e-03, -4.2115e-02,  3.5574e-03, -2.6637e-02, -6.5588e-03,\n",
      "         -7.1057e-02, -4.8337e-02, -2.7603e-02, -2.0828e-02,  3.5094e-02,\n",
      "         -1.4644e-02, -5.9428e-02,  5.6081e-03, -6.4734e-03, -2.9215e-02,\n",
      "          2.0739e-02, -5.0090e-02, -7.6981e-02,  2.1169e-02,  3.5010e-02,\n",
      "          7.1981e-02, -1.5890e-02,  2.9133e-02, -3.5402e-02,  1.8451e-02,\n",
      "         -2.0290e-02,  4.0959e-02,  2.7879e-02, -4.1952e-02,  4.1566e-02,\n",
      "         -1.7849e-02, -1.0722e-02,  6.2622e-02, -1.1447e-02,  6.1227e-02,\n",
      "         -5.8265e-02,  4.6275e-02,  4.0553e-02, -1.6143e-02, -6.4136e-02,\n",
      "         -4.5480e-02,  1.8065e-02, -3.1474e-02,  2.2731e-02, -6.5371e-02,\n",
      "          6.0874e-02,  9.7665e-03,  2.6593e-02, -3.1757e-02,  1.7590e-02,\n",
      "          1.5961e-02, -6.4487e-02, -1.1364e-02, -1.1512e-02, -1.4003e-02,\n",
      "         -1.6119e-02, -5.4845e-02,  4.5741e-02,  1.8967e-02, -2.1944e-03,\n",
      "         -5.6871e-03,  1.4872e-02, -9.8805e-03, -2.6129e-02, -2.2566e-02,\n",
      "         -2.7182e-02, -3.6773e-02,  2.9136e-02,  5.1151e-02,  3.5384e-02,\n",
      "         -9.7700e-03,  1.3025e-03, -3.2752e-02, -2.7354e-02,  2.9952e-02,\n",
      "         -3.3268e-02, -1.9780e-02, -1.6176e-02, -9.2057e-03, -1.0080e-02,\n",
      "          6.6744e-02, -1.8710e-02,  1.5577e-03, -8.5588e-03,  2.0381e-02,\n",
      "          5.2312e-02,  7.9516e-02,  2.1172e-03, -2.4941e-02,  7.6665e-03,\n",
      "          1.9416e-02, -8.0348e-03, -2.4437e-02, -3.2883e-02, -1.7940e-03,\n",
      "          1.0857e-02,  1.2347e-02, -1.4953e-02, -2.9909e-02, -3.2607e-02,\n",
      "         -6.9266e-03, -1.4678e-02,  1.4817e-02,  1.1462e-02,  5.0754e-02,\n",
      "         -1.7927e-02,  5.8373e-02, -7.4348e-02, -9.3015e-02, -5.5329e-02,\n",
      "         -4.2668e-02,  2.2664e-02, -4.8816e-02,  4.8153e-03, -3.6126e-02,\n",
      "         -3.1603e-02, -1.8668e-02, -1.5056e-02, -1.8078e-02,  1.7548e-02,\n",
      "          1.3640e-02,  1.0871e-02,  3.6860e-03,  3.6338e-02, -2.4497e-02,\n",
      "          3.1818e-03,  8.9249e-04,  1.6301e-02, -2.1362e-02,  5.9846e-02,\n",
      "          8.1494e-03,  4.7002e-03,  2.6472e-02,  1.2886e-02,  4.4163e-02,\n",
      "          2.5929e-02,  2.5925e-03, -2.4992e-02, -4.8442e-02,  5.7998e-02,\n",
      "         -1.8945e-02, -8.7498e-03,  1.5031e-02, -4.2475e-03, -4.0982e-02,\n",
      "          1.6871e-02,  3.9960e-02,  3.2482e-02,  2.3349e-02,  1.2687e-02,\n",
      "          1.9958e-03]], device='cuda:0', requires_grad=True) torch.Size([2, 256])\n",
      "Parameter containing:\n",
      "tensor([-0.0343,  0.0108], device='cuda:0', requires_grad=True) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "params = dict()\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    params['w'+str(i)] = param\n",
    "    print(param, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96539da1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 44.53125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2b9bfe8c4c65>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(self.data[idx], dtype=torch.float32)\n",
      "<ipython-input-4-2b9bfe8c4c65>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.label[idx], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "y_true = list()\n",
    "y_pred = list()\n",
    "lstm_h = list()\n",
    "last_fc = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(sequence_length, batch_size, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        o, outputs = model(images)\n",
    "        _, predicted = torch.max(o.data, 1)\n",
    "        y_true.extend(labels)\n",
    "        y_pred.extend(predicted)\n",
    "        lstm_h.extend(outputs)\n",
    "        last_fc.extend(o)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) \n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b6495b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0')],\n",
       " [tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0')])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4e4876b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc106edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_index = list()\n",
    "for i, pred in enumerate(y_pred):\n",
    "    if pred == 0:\n",
    "        bad_index.append(i)\n",
    "print(bad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "af31823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_samples = len(testset) - (len(testset)%batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c6c1162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(testset)//batch_size = 2 \n",
    "# sequence_length = 18\n",
    "# len(lstm_h) = 2*18\n",
    "print(len(lstm_h))\n",
    "print(lstm_h[0].shape) #num_layers, batch_size, hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "da619c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-7.5187e-02,  2.2605e-02,  2.4008e-02,  ...,  2.1915e-01,\n",
       "           -8.5587e-02,  2.4571e-01],\n",
       "          [-2.6804e-01,  1.0029e-01,  6.6043e-02,  ...,  1.4403e-01,\n",
       "            3.4353e-02,  1.8264e-02],\n",
       "          [-3.0316e-02,  3.8239e-01,  1.8399e-02,  ...,  1.1955e-01,\n",
       "           -3.6300e-01, -6.6691e-02],\n",
       "          ...,\n",
       "          [ 1.6575e-02,  9.9467e-01, -3.4478e-02,  ...,  4.5354e-03,\n",
       "            6.9323e-03, -1.8976e-03],\n",
       "          [-1.6052e-02,  9.1037e-01, -1.3856e-02,  ...,  1.2897e-02,\n",
       "           -5.7702e-02,  2.8490e-01],\n",
       "          [ 1.1527e-02,  8.7045e-01, -4.5849e-03,  ...,  9.2885e-04,\n",
       "           -2.1635e-01,  7.0458e-02]],\n",
       "\n",
       "         [[-2.3767e-02,  1.5613e-01, -8.1646e-02,  ..., -1.3176e-01,\n",
       "            1.9233e-02,  2.2309e-02],\n",
       "          [-1.0631e-02,  3.9692e-03, -4.5396e-02,  ..., -9.1430e-02,\n",
       "           -3.1552e-04,  7.1993e-03],\n",
       "          [-7.2483e-03,  5.4823e-02, -1.5646e-02,  ..., -6.4968e-02,\n",
       "           -7.5864e-03, -6.0242e-03],\n",
       "          ...,\n",
       "          [-6.7833e-04,  6.2016e-02, -8.3886e-04,  ..., -3.6646e-02,\n",
       "           -8.7247e-04, -1.1489e-03],\n",
       "          [-5.3682e-04,  5.0430e-02, -2.5191e-03,  ..., -2.1473e-02,\n",
       "           -1.0153e-04, -7.6393e-04],\n",
       "          [-4.6684e-04,  6.1863e-02, -1.4182e-03,  ..., -1.8836e-02,\n",
       "           -5.8913e-05, -2.4935e-04]]],\n",
       "\n",
       "\n",
       "        [[[ 3.3306e-01, -2.0126e-01, -1.4899e-01,  ..., -8.6045e-02,\n",
       "            2.7493e-01, -1.8027e-01],\n",
       "          [ 1.1964e-02, -8.1539e-02, -4.0572e-02,  ..., -8.6398e-03,\n",
       "            1.0381e-02, -3.6862e-01],\n",
       "          [ 7.9607e-03,  1.1099e-01,  2.6995e-02,  ..., -4.5655e-02,\n",
       "            2.0899e-02, -2.0589e-01],\n",
       "          ...,\n",
       "          [-9.1283e-02,  9.5224e-01, -3.1141e-01,  ...,  1.8394e-03,\n",
       "           -7.8112e-03,  1.3965e-01],\n",
       "          [ 9.6113e-02,  9.1842e-01, -6.1726e-02,  ...,  6.4987e-02,\n",
       "           -2.1232e-02,  3.9673e-03],\n",
       "          [-4.5106e-02,  8.7450e-01, -6.1362e-02,  ...,  2.6682e-02,\n",
       "            1.8763e-02, -2.2927e-02]],\n",
       "\n",
       "         [[ 1.7068e-01,  4.5601e-02,  4.2885e-02,  ..., -6.1939e-02,\n",
       "           -9.8751e-02, -2.9087e-02],\n",
       "          [-8.2751e-03,  1.3566e-01, -3.7331e-02,  ..., -1.5672e-01,\n",
       "            2.3288e-02,  4.6254e-02],\n",
       "          [-1.4781e-02,  2.0616e-03, -2.2735e-02,  ..., -4.3472e-02,\n",
       "           -1.7703e-02,  2.6952e-02],\n",
       "          ...,\n",
       "          [-7.6755e-04,  2.0771e-02, -2.1948e-04,  ..., -1.3766e-02,\n",
       "           -8.6886e-05, -2.7908e-05],\n",
       "          [-1.9557e-03,  4.5802e-02, -3.6048e-03,  ..., -3.4960e-02,\n",
       "           -4.5917e-04, -5.8538e-05],\n",
       "          [-4.9920e-04,  7.8959e-03, -1.0669e-03,  ..., -1.3373e-02,\n",
       "           -6.9462e-05,  2.4015e-04]]],\n",
       "\n",
       "\n",
       "        [[[-8.5481e-02,  6.3070e-02,  1.0714e-01,  ...,  5.5613e-02,\n",
       "            3.1249e-01, -1.3600e-01],\n",
       "          [-3.6573e-01,  3.0717e-01,  6.4067e-02,  ...,  9.8456e-02,\n",
       "            9.0806e-02, -1.0604e-01],\n",
       "          [-4.1462e-02,  1.8888e-01,  9.0107e-03,  ...,  2.1461e-02,\n",
       "            2.9299e-02, -1.6349e-02],\n",
       "          ...,\n",
       "          [ 1.7185e-01,  8.6266e-01, -1.1086e-01,  ...,  2.1627e-02,\n",
       "           -1.0440e-02,  2.0003e-02],\n",
       "          [ 2.6413e-03,  9.1481e-01, -8.2264e-02,  ...,  3.3576e-02,\n",
       "           -9.9397e-03,  2.6929e-01],\n",
       "          [-1.0950e-02,  9.3474e-01, -1.9327e-01,  ...,  4.7883e-02,\n",
       "           -2.0427e-02,  9.4466e-02]],\n",
       "\n",
       "         [[-1.6734e-02,  7.7774e-02, -7.9102e-02,  ..., -9.9244e-02,\n",
       "            1.8429e-02,  6.4286e-03],\n",
       "          [-1.7556e-02, -4.0956e-04, -1.1413e-01,  ..., -4.8570e-02,\n",
       "            4.8696e-03,  1.1185e-02],\n",
       "          [-1.1122e-02,  1.8436e-02, -1.1500e-01,  ..., -5.3134e-02,\n",
       "            6.8424e-03,  1.6249e-02],\n",
       "          ...,\n",
       "          [-9.4855e-04,  1.8871e-02, -7.7183e-04,  ..., -2.0214e-02,\n",
       "           -8.3400e-05,  9.7685e-05],\n",
       "          [-5.1296e-04,  2.1115e-01,  1.4259e-03,  ..., -3.9725e-02,\n",
       "           -1.2744e-03, -4.5834e-03],\n",
       "          [-5.8835e-04,  2.9355e-02, -1.3904e-03,  ..., -1.1678e-02,\n",
       "           -2.4919e-05, -5.5144e-05]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.0764e-02,  2.2133e-01,  1.1780e-01,  ...,  4.0152e-01,\n",
       "            6.5828e-03, -6.9059e-02],\n",
       "          [ 9.0981e-02,  5.7998e-01,  6.0764e-02,  ...,  1.8828e-01,\n",
       "           -8.9910e-02,  1.9575e-01],\n",
       "          [ 3.6627e-01,  6.1002e-01,  4.0905e-02,  ...,  9.0687e-02,\n",
       "           -2.1334e-01,  3.4983e-01],\n",
       "          ...,\n",
       "          [ 4.0300e-03,  9.0626e-01, -7.1859e-02,  ..., -1.1483e-02,\n",
       "            1.1030e-03, -1.1405e-03],\n",
       "          [ 2.1607e-03,  9.5163e-01, -1.0457e-02,  ..., -9.4848e-03,\n",
       "           -1.7910e-03, -8.3757e-03],\n",
       "          [ 3.8877e-03,  7.7308e-01, -1.3257e-03,  ..., -1.3311e-03,\n",
       "           -1.5653e-02,  4.8403e-01]],\n",
       "\n",
       "         [[-1.2617e-03, -1.0241e-02, -1.1381e-01,  ..., -2.6071e-02,\n",
       "           -4.0766e-02,  4.6428e-02],\n",
       "          [ 5.8380e-03,  2.8975e-01,  1.0835e-02,  ..., -7.5784e-02,\n",
       "           -6.1235e-02, -1.3879e-01],\n",
       "          [ 3.6226e-04,  4.2371e-01,  2.7211e-05,  ..., -2.8133e-02,\n",
       "           -2.3625e-04, -6.6671e-03],\n",
       "          ...,\n",
       "          [-1.1874e-03,  3.1566e-02, -1.2808e-03,  ..., -2.5803e-02,\n",
       "           -3.2556e-04,  2.4461e-04],\n",
       "          [-1.9130e-03,  3.4224e-02, -4.9056e-03,  ..., -3.2425e-02,\n",
       "           -5.2118e-04,  2.6007e-04],\n",
       "          [-8.8061e-04,  4.7160e-02,  7.6660e-04,  ..., -3.4430e-02,\n",
       "           -1.0321e-03, -1.4874e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5032e-01,  5.4694e-02,  3.8566e-01,  ..., -1.1573e-01,\n",
       "            6.7592e-02, -4.7360e-03],\n",
       "          [ 8.9205e-03, -1.8877e-01,  1.6643e-01,  ..., -7.2698e-03,\n",
       "           -6.8129e-02,  5.7430e-02],\n",
       "          [-1.0979e-02, -3.4827e-02,  2.2514e-02,  ...,  3.1892e-02,\n",
       "           -9.9293e-03,  1.4682e-01],\n",
       "          ...,\n",
       "          [-2.8833e-03,  9.0329e-01, -1.6660e-02,  ..., -7.4103e-03,\n",
       "            5.3081e-02,  4.7690e-02],\n",
       "          [ 2.4730e-01,  9.7389e-01,  1.5643e-02,  ..., -1.5969e-03,\n",
       "           -1.7294e-02,  3.1236e-02],\n",
       "          [ 3.2068e-02,  9.4015e-01,  5.4075e-03,  ..., -2.1971e-03,\n",
       "           -2.3596e-02,  2.0694e-01]],\n",
       "\n",
       "         [[ 2.9482e-02,  2.8679e-02,  2.1949e-02,  ..., -4.7969e-02,\n",
       "           -1.3275e-01, -1.8740e-01],\n",
       "          [ 3.0572e-02,  1.8255e-01,  7.0858e-03,  ..., -8.4500e-02,\n",
       "           -2.6723e-02, -1.0502e-01],\n",
       "          [-2.7717e-04,  2.8196e-01, -1.9430e-03,  ..., -5.0797e-02,\n",
       "           -1.4913e-03, -1.9515e-02],\n",
       "          ...,\n",
       "          [-1.2512e-03,  5.8487e-02, -1.8465e-03,  ..., -2.9997e-02,\n",
       "           -2.8855e-04, -2.1381e-04],\n",
       "          [-6.6214e-04,  1.7763e-02, -2.4904e-04,  ..., -1.9583e-02,\n",
       "           -1.3455e-04, -1.7651e-04],\n",
       "          [-2.5741e-04,  1.4575e-01,  7.4774e-04,  ..., -2.6588e-02,\n",
       "           -6.5038e-04, -3.6139e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 4.2951e-02,  2.6087e-01, -6.3307e-01,  ..., -1.5232e-02,\n",
       "            8.7691e-02, -3.5770e-03],\n",
       "          [ 1.6700e-01, -2.8505e-01, -2.6537e-02,  ..., -4.8242e-02,\n",
       "           -5.6692e-01,  3.2053e-01],\n",
       "          [-3.4055e-02, -3.6860e-01, -2.5897e-01,  ..., -4.4802e-04,\n",
       "           -4.4164e-03,  4.4410e-01],\n",
       "          ...,\n",
       "          [ 1.4796e-03,  9.8003e-01, -1.2036e-02,  ...,  2.6544e-04,\n",
       "           -1.0979e-02,  3.8962e-01],\n",
       "          [-4.3030e-01,  9.6566e-01, -2.9166e-02,  ..., -6.1066e-03,\n",
       "           -2.2443e-02,  3.4417e-01],\n",
       "          [-8.3178e-03,  9.8639e-01, -3.0707e-02,  ..., -1.2394e-03,\n",
       "            1.7618e-02, -3.6362e-03]],\n",
       "\n",
       "         [[ 4.8972e-02, -3.4326e-02,  3.8750e-02,  ...,  1.4979e-02,\n",
       "           -5.3073e-02, -4.4186e-02],\n",
       "          [ 3.1855e-03,  5.4908e-01,  1.9502e-03,  ..., -1.1422e-01,\n",
       "           -5.3928e-03, -1.0057e-01],\n",
       "          [-3.2124e-04,  3.5198e-01, -7.5026e-05,  ..., -1.7079e-02,\n",
       "           -7.5626e-05, -4.4347e-03],\n",
       "          ...,\n",
       "          [-1.8833e-03,  8.2811e-02, -2.4590e-03,  ..., -3.5285e-02,\n",
       "           -2.8223e-04, -1.0154e-03],\n",
       "          [-7.5017e-04,  2.3897e-02, -1.5672e-03,  ..., -1.6594e-02,\n",
       "           -8.2951e-06,  2.5782e-04],\n",
       "          [-7.7119e-04,  1.5588e-02, -1.7272e-03,  ..., -1.7722e-02,\n",
       "           -2.4530e-05,  2.3827e-04]]]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_samples, n_layers, sequence_length, hidden_size\n",
    "\n",
    "reshaped = torch.zeros(used_samples, num_layers, sequence_length, hidden_size)\n",
    "n_loops = used_samples//batch_size\n",
    "\n",
    "for i in range(n_loops):\n",
    "    temp = torch.zeros(sequence_length, num_layers, batch_size, hidden_size)\n",
    "    for j in range(sequence_length):\n",
    "        temp[j] = lstm_h[j]\n",
    "    #batch_size, num_layers, sequence_length, hidden_size 순서로 변경\n",
    "    temp = temp.permute(2, 1, 0, 3)\n",
    "    reshaped[i*batch_size:(i+1)*batch_size] = temp\n",
    "print(reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "30e6d573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['w0', 'w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9'])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fe429ac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(params['w8'][0].shape, params['w9'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "51fb9462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256]), torch.Size([256]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reshaped[0][1][17].shape, params['w8'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c07cc168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0148, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check whether last_h * w + b == last_fc\n",
    "print(torch.matmul(reshaped[0][1][17].to(device), params['w8'][0]) + params['w9'][0])\n",
    "print(last_fc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4532d690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(62, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#get index of argmax(without considering bias)\n",
    "b1 = reshaped[0][1][17].to(device)*params['w8'][0]\n",
    "max_b1 = torch.argmax(b1)\n",
    "print(max_b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fd8a11c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#W_h for input gate\n",
    "w_hh = params['w1'][:hidden_size, :]\n",
    "w_hh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0f88a957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#W_x for input gate\n",
    "w_ih = params['w0'][:hidden_size, :]\n",
    "w_ih.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ba27b347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(215, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# second layer....\n",
    "b2 = reshaped[0][1][16].to(device)*w_hh[max_b1]\n",
    "max_b2 = torch.argmax(b2)\n",
    "print(max_b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "35e5b338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(92, device='cuda:0') tensor(0.2815, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2b9bfe8c4c65>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(self.data[idx], dtype=torch.float32)\n",
      "<ipython-input-4-2b9bfe8c4c65>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.label[idx], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "p18 = testset[0][0][17].to(device) * w_ih[max_b1]\n",
    "max_p18 = torch.argmax(p18)\n",
    "print(max_p18, p18[max_p18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a172761e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(79, device='cuda:0') tensor(0.2302, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2b9bfe8c4c65>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(self.data[idx], dtype=torch.float32)\n",
      "<ipython-input-4-2b9bfe8c4c65>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.label[idx], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "p17 = testset[0][0][16].to(device) * w_ih[max_p18]\n",
    "max_p17 = torch.argmax(p17)\n",
    "print(max_p17, p17[max_p17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a3d74f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12, device='cuda:0') tensor(0.2424, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2b9bfe8c4c65>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(self.data[idx], dtype=torch.float32)\n",
      "<ipython-input-4-2b9bfe8c4c65>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.label[idx], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "p16 = testset[0][0][15].to(device) * w_ih[max_p17]\n",
    "max_p16 = torch.argmax(p16)\n",
    "print(max_p16, p16[max_p16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0206f11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(82, device='cuda:0') tensor(0.2346, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2b9bfe8c4c65>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(self.data[idx], dtype=torch.float32)\n",
      "<ipython-input-4-2b9bfe8c4c65>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.label[idx], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "p15 = testset[0][0][14].to(device) * w_ih[max_p16]\n",
    "max_p15 = torch.argmax(p15)\n",
    "print(max_p15, p15[max_p15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "29d9fc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(41, device='cuda:0') tensor(0.3145, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2b9bfe8c4c65>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(self.data[idx], dtype=torch.float32)\n",
      "<ipython-input-4-2b9bfe8c4c65>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.label[idx], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "p14 = testset[0][0][13].to(device) * w_ih[max_p15]\n",
    "max_p14 = torch.argmax(p14)\n",
    "print(max_p14, p14[max_p14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "53e01ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(72, device='cuda:0') tensor(0.2042, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2b9bfe8c4c65>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(self.data[idx], dtype=torch.float32)\n",
      "<ipython-input-4-2b9bfe8c4c65>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.label[idx], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "p13 = testset[0][0][12].to(device) * w_ih[max_p14]\n",
    "max_p13 = torch.argmax(p13)\n",
    "print(max_p13, p13[max_p13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8fb6483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(testset[0])\n",
    "data = testset[0][0].to(device)\n",
    "data[0].shape\n",
    "params['w0'].shape\n",
    "data = data.reshape((128, 18))\n",
    "lstm_x = torch.matmul(params['w0'], data) + params['w2'][:, None]\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g9star",
   "language": "python",
   "name": "g9star"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
